{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBq/hyktBSLsz5wq66fBoL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imanuni/imanuni/blob/main/model-de-chat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "DMrSnkFRRRtZ",
        "outputId": "aff949c4-e9e5-4a18-e807-aad958ea1489"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-09d1ce4143ee>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertForTokenClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataCollatorForTokenClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Charger et préparer les données\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForTokenClassification, BertConfig, Trainer, TrainingArguments\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from datasets import load_dataset, load_metric, DatasetDict\n",
        "\n",
        "# Charger et préparer les données\n",
        "dataset = load_dataset(\"conll2003\")  # Remplacez par votre propre jeu de données annoté\n",
        "\n",
        "# Prétraitement\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples['tokens'], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples['ner_tags']):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_and_align_labels, batched=True)\n"
      ],
      "metadata": {
        "id": "jsmSjs4rRa8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Chargement du modèle BERT\n",
        "model = BertForTokenClassification.from_pretrained('bert-base-cased', num_labels=len(dataset['train'].features['ner_tags'].feature.names))\n",
        "\n",
        "# Préparer l'entraînement\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")"
      ],
      "metadata": {
        "id": "3TJTp--DRhdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "# Entraîner le modèle\n",
        "trainer.train()\n",
        "\n",
        "# Évaluation du modèle\n",
        "metric = load_metric(\"seqeval\")"
      ],
      "metadata": {
        "id": "Vjp_pG7uRyL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "\n",
        "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "    return {\n",
        "        \"precision\": results[\"overall_precision\"],\n",
        "        \"recall\": results[\"overall_recall\"],\n",
        "        \"f1\": results[\"overall_f1\"],\n",
        "        \"accuracy\": results[\"overall_accuracy\"],\n",
        "    }\n",
        "\n",
        "trainer.evaluate()\n",
        "\n",
        "# Sauvegarde du modèle\n",
        "model.save_pretrained(\"./saved_model\")\n",
        "tokenizer.save_pretrained(\"./saved_model\")"
      ],
      "metadata": {
        "id": "XYYgk2XeR53K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assurez-vous d'avoir installé les bibliothèques nécessaires avant d'exécuter le code :"
      ],
      "metadata": {
        "id": "svmqNUolSH83"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers datasets seqeval"
      ],
      "metadata": {
        "id": "nbHkRjOaSI36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "donne moi un examplaire des resultats"
      ],
      "metadata": {
        "id": "puk0s1VwSOR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForTokenClassification\n",
        "import numpy as np\n",
        "\n",
        "# Charger le modèle et le tokenizer sauvegardés\n",
        "model = BertForTokenClassification.from_pretrained('./saved_model')\n",
        "tokenizer = BertTokenizer.from_pretrained('./saved_model')\n",
        "\n",
        "# Exemples de textes journalistiques\n",
        "texts = [\n",
        "    \"Le président a déclaré que les nouvelles mesures économiques seront bénéfiques pour le pays.\",\n",
        "    \"Le ministre des Affaires étrangères a annoncé une coopération renforcée avec les pays voisins.\"\n",
        "]\n",
        "\n",
        "# Fonction pour prédire et afficher les résultats\n",
        "def predict_and_display(texts):\n",
        "    for text in texts:\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, is_split_into_words=True)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        predictions = torch.argmax(outputs.logits, dim=2)\n",
        "        tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
        "\n",
        "        print(f\"Texte : {text}\")\n",
        "        print(\"Déclarations politiques extraites :\")\n",
        "\n",
        "        current_declaration = []\n",
        "        for token, label in zip(tokens, predictions[0].numpy()):\n",
        "            if label == 1:  # Supposons que l'étiquette 1 correspond aux déclarations politiques\n",
        "                current_declaration.append(token)\n",
        "            else:\n",
        "                if current_declaration:\n",
        "                    print(\" \".join(current_declaration).replace(' ##', ''))\n",
        "                    current_declaration = []\n",
        "\n",
        "        if current_declaration:\n",
        "            print(\" \".join(current_declaration).replace(' ##', ''))\n",
        "        print(\"\\n\")\n",
        "\n",
        "# Prédire et afficher les résultats pour les textes de test\n",
        "predict_and_display(texts)"
      ],
      "metadata": {
        "id": "lJGK3ctISUhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Résultats attendus :\n",
        "En exécutant le code ci-dessus, vous obtiendrez une sortie similaire à celle-ci (les résultats réels dépendront des performances du modèle entraîné) :\n",
        "Texte : Le président a déclaré que les nouvelles mesures économiques seront bénéfiques pour le pays.\n",
        "Déclarations politiques extraites :\n",
        "Le président a déclaré\n",
        "\n",
        "Texte : Le ministre des Affaires étrangères a annoncé une coopération renforcée avec les pays voisins.\n",
        "Déclarations politiques extraites :\n",
        "Le ministre des Affaires étrangères a annoncé"
      ],
      "metadata": {
        "id": "i2ljLoWFSaYV"
      }
    }
  ]
}